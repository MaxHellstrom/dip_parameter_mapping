{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "path_working_dir = Path(os.path.abspath(\"\"))\n",
    "path_repo = path_working_dir.parents[1]\n",
    "sys.path.insert(0, str(path_working_dir.parents[1].absolute()))\n",
    "\n",
    "path_data_raw = path_working_dir.parent / \"data_raw\"\n",
    "path_data_parsed = path_working_dir.parent / \"data_parsed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from utils.gridplot import GridPlot\n",
    "from utils.physics import simulate_complex_noise, spgr_signal\n",
    "from utils.plotting import (\n",
    "    plot_estimate_b1_corr,\n",
    "    plot_estimate_mask,\n",
    "    plot_estimate_param,\n",
    "    plot_estimate_signal,\n",
    ")\n",
    "from utils.statistics import (\n",
    "    T1_VFA_NLLS_estimator_parallel,\n",
    "    estimate_sigma2_from_residuals,\n",
    ")\n",
    "\n",
    "plt.rcParams[\"image.interpolation\"] = \"None\"\n",
    "plt.rcParams[\"font.size\"] = 9.0\n",
    "\n",
    "\n",
    "def get_dataset_name(str_application, str_shape, str_setting, str_noise, str_pat_name):\n",
    "    return f\"{str_application}__{str_pat_name}_{str_shape}_{str_setting}_{str_noise}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat_names = [\"Pat_04\"]\n",
    "\n",
    "for pat_name in pat_names:\n",
    "    params = dict(\n",
    "        name_application=\"T1_VFA\",\n",
    "        setting_name=\"fa\",\n",
    "        pat_name=pat_name,\n",
    "        param_names=[\"S0\", \"T1\"],\n",
    "        param_units=[\"a.u.\", \"seconds\"],\n",
    "        fa_deg=[2, 4, 11, 13, 15],\n",
    "        fa=np.deg2rad([2, 4, 11, 13, 15]),\n",
    "        tr=6.8 * 1e-3,\n",
    "        p_scales=[9.8, 1],\n",
    "        lims_p=((0, 15), (0, 6)),\n",
    "        lims_diff_p=((-1.5, +1.5), (-0.6, +0.6)),\n",
    "        lims_y=(0, 1),\n",
    "        lims_diff_y=(-0.05, +0.05),\n",
    "        lims_b1=(0, 2),\n",
    "        noise_std=0.02,\n",
    "        init_guess=[8, 4],\n",
    "        bounds=((0, 0), (100, 6)),\n",
    "        mask_bound=0.3,\n",
    "    )\n",
    "    dp = path_data_raw / \"brainweb\" / params[\"pat_name\"]\n",
    "\n",
    "    p_ref = np.stack(\n",
    "        [\n",
    "            params[\"p_scales\"][idx_param]\n",
    "            * np.load(dp / f\"{params['param_names'][idx_param]}.npy\")\n",
    "            for idx_param in range(len(params[\"param_names\"]))\n",
    "        ],\n",
    "        axis=0,\n",
    "    ).swapaxes(1, 3)\n",
    "\n",
    "    print(f\"loaded p_ref with shape: {p_ref.shape}\")\n",
    "\n",
    "    mask_bound = p_ref[1, ...] > params[\"mask_bound\"]\n",
    "\n",
    "    path_to_corrected_mask = dp / \"mask_corrected.npy\"\n",
    "\n",
    "    if path_to_corrected_mask.exists():\n",
    "        mask_tissue = np.load(path_to_corrected_mask).swapaxes(0, 2)\n",
    "\n",
    "    else:\n",
    "        mask_tissue = np.load(dp / \"mask.npy\").swapaxes(0, 2)\n",
    "\n",
    "    mask = np.logical_and.reduce([mask_bound, mask_tissue])\n",
    "    b1_corr = mask.astype(float)\n",
    "\n",
    "    print(f\"loaded mask with shape: {mask.shape}\")\n",
    "\n",
    "    export_plots = True\n",
    "\n",
    "    dataset_name = get_dataset_name(\n",
    "        str_application=params[\"name_application\"],\n",
    "        str_shape=f\"shape_{mask.shape[1]}_{mask.shape[2]}_{mask.shape[0]}\",\n",
    "        str_setting=params[\"setting_name\"]\n",
    "        + str(params[\"fa_deg\"]).replace(\", \", \"_\").replace(\"[\", \"_\").replace(\"]\", \"\"),\n",
    "        str_noise=\"noise_\" + str(params[\"noise_std\"]),\n",
    "        str_pat_name=params[\"pat_name\"],\n",
    "    )\n",
    "\n",
    "    path_dataset = path_data_parsed / dataset_name.split(\"__\")[0] / dataset_name\n",
    "    for item in (\"source\", \"plots\"):\n",
    "        tmp = path_dataset / item\n",
    "        tmp.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    y_ref = np.asarray(\n",
    "        [\n",
    "            spgr_signal(\n",
    "                S0=p_ref[0, idx_z, :, :],\n",
    "                T1=p_ref[1, idx_z, :, :],\n",
    "                FA=params[\"fa\"],\n",
    "                TR=params[\"tr\"],\n",
    "                B1_corr=b1_corr[idx_z, :, :],\n",
    "                mask=mask[idx_z, :, :],\n",
    "            )\n",
    "            for idx_z in range(mask.shape[0])\n",
    "        ]\n",
    "    ).swapaxes(0, 1)\n",
    "\n",
    "    print(f\"calculated y_ref with shape: {y_ref.shape}\")\n",
    "\n",
    "    y_scales = np.zeros(y_ref.shape[0:2])\n",
    "    for idx_z in range(y_ref.shape[1]):\n",
    "        for idx_s in range(y_ref.shape[0]):\n",
    "            y_scales[idx_s, idx_z] = y_ref[idx_s, idx_z, ...].max()\n",
    "\n",
    "    y = np.asarray(\n",
    "        [\n",
    "            simulate_complex_noise(\n",
    "                image=y_ref[:, idx_z, :, :], noise_std=params[\"noise_std\"]\n",
    "            )\n",
    "            for idx_z in range(y_ref.shape[1])\n",
    "        ]\n",
    "    ).swapaxes(0, 1)\n",
    "\n",
    "    print(f\"calculated y with shape: {y_ref.shape}\")\n",
    "\n",
    "    for idx_z in tqdm(range(mask.shape[0]), desc=\"plotting dataset\"):\n",
    "        plot_estimate_b1_corr(\n",
    "            b1_corr=b1_corr[idx_z, :, :],\n",
    "            mask=mask[idx_z, :, :],\n",
    "            path_export=path_dataset / \"plots\" / f\"b1_corr_z_{idx_z}.png\",\n",
    "        )\n",
    "        plot_estimate_mask(\n",
    "            mask=mask[idx_z, :, :],\n",
    "            path_export=path_dataset / \"plots\" / f\"mask_z_{idx_z}.png\",\n",
    "        )\n",
    "\n",
    "        plot_estimate_signal(\n",
    "            y=y[:, idx_z, :, :],\n",
    "            y_ref=y_ref[:, idx_z, :, :],\n",
    "            mask=mask[idx_z, ...],\n",
    "            lims=params[\"lims_y\"],\n",
    "            lims_diff=params[\"lims_diff_y\"],\n",
    "            path_export=path_dataset / \"plots\" / f\"y_versus_y_ref_z_{idx_z}.png\",\n",
    "            name_est=\"y\",\n",
    "            name_ref=\"y_ref\",\n",
    "        )\n",
    "\n",
    "    p_nlls = []\n",
    "    y_nlls = []\n",
    "\n",
    "    for idx_z in tqdm(\n",
    "        range(mask.shape[0]), desc=\"calculating and plotting NLLS estimates\"\n",
    "    ):\n",
    "        nlls = T1_VFA_NLLS_estimator_parallel(\n",
    "            y=y[:, idx_z, :, :],\n",
    "            FA_values=params[\"fa\"],\n",
    "            TR=params[\"tr\"],\n",
    "            B1_corr=b1_corr[idx_z, :, :],\n",
    "            mask=mask[idx_z, :, :],\n",
    "            bounds=params[\"bounds\"],\n",
    "        )\n",
    "\n",
    "        p_nlls.append(nlls)\n",
    "\n",
    "        plot_estimate_param(\n",
    "            p_est=nlls,\n",
    "            p_ref=p_ref[:, idx_z, :, :],\n",
    "            lims_p=params[\"lims_p\"],\n",
    "            lims_diff=params[\"lims_diff_p\"],\n",
    "            lims_hist=params[\"lims_p\"],\n",
    "            name_est=\"nlls\",\n",
    "            name_ref=\"ref\",\n",
    "            param_names=params[\"param_names\"],\n",
    "            param_units=params[\"param_units\"],\n",
    "            path_export=path_dataset / \"plots\" / f\"p_nlls_versus_ref_z_{idx_z}.png\",\n",
    "            mask=mask[idx_z],\n",
    "        )\n",
    "\n",
    "        nlls = spgr_signal(\n",
    "            S0=nlls[0, :, :],\n",
    "            T1=nlls[1, :, :],\n",
    "            FA=params[\"fa\"],\n",
    "            TR=params[\"tr\"],\n",
    "            mask=mask[idx_z, :, :],\n",
    "            B1_corr=b1_corr[idx_z, :, :],\n",
    "        )\n",
    "\n",
    "        y_nlls.append(nlls)\n",
    "\n",
    "        plot_estimate_signal(\n",
    "            y=nlls,\n",
    "            y_ref=y[:, idx_z, :, :],\n",
    "            mask=mask[idx_z, ...],\n",
    "            lims=params[\"lims_y\"],\n",
    "            lims_diff=params[\"lims_diff_y\"],\n",
    "            path_export=path_dataset / \"plots\" / f\"y_nlls_versus_y_z_{idx_z}.png\",\n",
    "            name_est=\"nlls\",\n",
    "            name_ref=\"y\",\n",
    "        )\n",
    "\n",
    "    p_nlls = np.asarray(p_nlls).swapaxes(0, 1)\n",
    "    y_nlls = np.asarray(y_nlls).swapaxes(0, 1)\n",
    "    r_nlls = y_nlls - y\n",
    "    np.save(path_dataset / \"source\" / \"p_nlls.npy\", p_nlls)\n",
    "    np.save(path_dataset / \"source\" / \"y_nlls.npy\", y_nlls)\n",
    "    np.save(path_dataset / \"source\" / \"r_nlls.npy\", r_nlls)\n",
    "    np.save(path_dataset / \"source\" / \"p_ref.npy\", p_ref)\n",
    "    np.save(path_dataset / \"source\" / \"mask.npy\", mask)\n",
    "    np.save(path_dataset / \"source\" / \"y.npy\", y)\n",
    "    np.save(path_dataset / \"source\" / \"y_ref.npy\", y_ref)\n",
    "    np.save(path_dataset / \"source\" / \"b1_corr.npy\", b1_corr)\n",
    "    np.savez(path_dataset / \"source\" / \"params.npz\", **params)\n",
    "\n",
    "    print(\"estimating noise level...\")\n",
    "    mask_expanded = np.stack(y.shape[0] * [mask])\n",
    "    sigma_2_whole_volume = estimate_sigma2_from_residuals(r=r_nlls[:, mask])\n",
    "\n",
    "    sigma_2_per_slice = []\n",
    "    for idx_z in range(mask.shape[0]):\n",
    "        sub_r = r_nlls[:, idx_z, :, :][:, mask[idx_z, :, :]]\n",
    "\n",
    "        sigma_2_per_slice.append(estimate_sigma2_from_residuals(r=sub_r))\n",
    "\n",
    "    sigma_per_slice_mean = [np.sqrt(np.mean(item)) for item in sigma_2_per_slice]\n",
    "\n",
    "    plot = GridPlot(ncols=3, nrows=1, size=(12, 4))\n",
    "    plot.axs[0, 0].hist(\n",
    "        r_nlls[mask_expanded], bins=100, label=\"residuals (whole volume)\"\n",
    "    )\n",
    "    plot.axs[0, 0].set(title=dataset_name)\n",
    "\n",
    "    plot.axs[0, 1].hist(sigma_2_whole_volume, bins=100, label=\"sigma_2 (whole volume)\")\n",
    "\n",
    "    plot.axs[0, 2].plot(sigma_per_slice_mean, \"*\", label=\"sigma_per_slice_mean\")\n",
    "    plot.axs[0, 2].plot(\n",
    "        [0, mask.shape[0]], 2 * [params[\"noise_std\"]], \"-k\", label=\"noise std\"\n",
    "    )\n",
    "\n",
    "    for idx_row in range(plot.nrows):\n",
    "        for idx_col in range(plot.ncols):\n",
    "            if (idx_row, idx_col) != (1, 1):\n",
    "                plot.axs[idx_row, idx_col].legend()\n",
    "\n",
    "    plot.export(path_dataset / \"plots\" / \"_noise_analysis.png\")\n",
    "    plt.close()\n",
    "\n",
    "    for idx_z in tqdm(range(mask.shape[0]), desc=\"saving dataset\"):\n",
    "        np.savez(\n",
    "            path_dataset / f\"dataset_idx_s_{idx_z:03d}.npz\",\n",
    "            y=y[:, idx_z, :, :],\n",
    "            y_ref=y_ref[:, idx_z, :, :],\n",
    "            mask=mask[idx_z, :, :],\n",
    "            p_nlls=p_nlls[:, idx_z, :, :],\n",
    "            p_ref=p_ref[:, idx_z, :, :],\n",
    "            fa=params[\"fa\"],\n",
    "            tr=params[\"tr\"],\n",
    "            b1_corr=b1_corr[idx_z, :, :],\n",
    "            init_guess=params[\"init_guess\"],\n",
    "            bounds=params[\"bounds\"],\n",
    "            param_names=params[\"param_names\"],\n",
    "            param_units=params[\"param_units\"],\n",
    "            name_application=params[\"name_application\"],\n",
    "            num_slices=mask.shape[0],\n",
    "            image_height=mask.shape[1],\n",
    "            image_width=mask.shape[2],\n",
    "            noise_std=params[\"noise_std\"],\n",
    "            lims_p=params[\"lims_p\"],\n",
    "            lims_y=params[\"lims_y\"],\n",
    "            estimated_noise_std=sigma_per_slice_mean[idx_z],  # used for training (\\ell)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
